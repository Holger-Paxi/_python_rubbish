{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% MODULES AND PACKAGES\n",
    "# importing modules\n",
    "import pandas as pd\n",
    "import processing\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import datetime as dt\n",
    "from csv import DictWriter\n",
    "\n",
    "import qgis\n",
    "from qgis.core import *\n",
    "import qgis.utils\n",
    "import processing.tools.general\n",
    "from processing import *\n",
    "from processing.core.Processing import Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qgis.core import *\n",
    "\n",
    "# Supply path to qgis install location\n",
    "QgsApplication.setPrefixPath('C:/PROGRA~1/QGIS32~1.3/apps/qgis', True)\n",
    "\n",
    "# Create a reference to the QgsApplication.  Setting the\n",
    "# second argument to False disables the GUI.\n",
    "qgs = QgsApplication([], False)\n",
    "\n",
    "# Load providers\n",
    "qgs.initQgis()\n",
    "\n",
    "# Write your code here to load some layers, use processing\n",
    "# algorithms, etc.\n",
    "\n",
    "# Finally, exitQgis() is called to remove the\n",
    "# provider and layer registries from memory\n",
    "qgs.exitQgis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% FUNCTIONS THAT RUN\n",
    "\n",
    "def Get_Vol_Area_shp(df_sc_index_2, temp_var_clip_sdat_file_loc, ts_name_GivenIndex_2):          # (df_sc_index_2):          # (df_sc_index_2, temp_var_clip_sdat_file_loc)\n",
    "# arg1: each row index in dataframe Arg_SC_dt_index; it is a dataframe\n",
    "# arg2: only one sdat file produced by Arg_TS_dt_index in process; it is a variable which refers the file location\n",
    "# arg3: only one temporary timestamp name for the sdat file given the index of the timestamp in process: it is a variable which refers the timestamp name given an index\n",
    "\n",
    "    # CLIPPING SUBCATCHMENTS\n",
    "    # Selection and clipping of each subcatchment\n",
    "\n",
    "    # input variables for clipping subcatchments\n",
    "    in_sc_sdat_file = temp_var_clip_sdat_file_loc                    #temp_var_clip_sdat_file_loc       # exe_clp['OUTPUT']\n",
    "    mask_sc_shp_file = '{}{}.shp'.format(loc_sc_folder, sc_name.iloc[df_sc_index_2,0])\n",
    "    # out_clip_sc_sdat_file = '{}{}_{}.sdat'.format(out_folder, ts_name.iloc[0,0], sc_name.iloc[0,0])\n",
    "\n",
    "    # CRBML via QGIS processing\n",
    "    exe_clp_sc = processing.run(\"gdal:cliprasterbymasklayer\",\\\n",
    "        {'INPUT':in_sc_sdat_file,\\\n",
    "        'MASK': mask_sc_shp_file,\\\n",
    "        'SOURCE_CRS':None,\\\n",
    "        'TARGET_CRS':None,\\\n",
    "        'NODATA':None,\\\n",
    "        'ALPHA_BAND':False,\\\n",
    "        'CROP_TO_CUTLINE':True,\\\n",
    "        'KEEP_RESOLUTION':False,\\\n",
    "        'SET_RESOLUTION':False,\\\n",
    "        'X_RESOLUTION':None,\\\n",
    "        'Y_RESOLUTION':None,\\\n",
    "        'MULTITHREADING':False,\\\n",
    "        'OPTIONS':'',\\\n",
    "        'DATA_TYPE':0,\\\n",
    "        'EXTRA':'',\\\n",
    "        'OUTPUT':'TEMPORARY_OUTPUT'})\n",
    "\n",
    "\n",
    "    # GETTING VOLUME AND AREA\n",
    "    # Getting the volume and area for each subcatchment to get the total depth\n",
    "\n",
    "    # input variables for getting the volume and area\n",
    "    in_va_sdat_file = exe_clp_sc['OUTPUT']\n",
    "    temp_out_va_dbf_file = '{}temp_va.shp'.format(out_folder)\n",
    "\n",
    "    # raster surface volume via QGIS processing                 # exe_va_sc = \n",
    "    processing.run(\"native:rastersurfacevolume\",\\\n",
    "        {'INPUT':in_va_sdat_file,\\\n",
    "        'BAND':1,\\\n",
    "        'LEVEL':0,\\\n",
    "        'METHOD':0,\\\n",
    "    #    'OUTPUT_HTML_FILE':'TEMPORARY_OUTPUT',\\\n",
    "        'OUTPUT_TABLE':temp_out_va_dbf_file})                   # 'TEMPORARY_OUTPUT'\n",
    "    \n",
    "\n",
    "    # CALCULATING PRECIPITATION DEPTH\n",
    "    # calculating precipitation depth (pd) from attribute table sdat file\n",
    "\n",
    "    in_pd_dbf_file = '{}temp_va.dbf'.format(out_folder)             # temp_out_va_dbf_file           # exe_va_sc['OUTPUT_TABLE']\n",
    "    attb_table = QgsVectorLayer(in_pd_dbf_file, '', 'ogr')\n",
    "    first_feature_table = attb_table.getFeature(0)\n",
    "    vol_mm_x_m2 = first_feature_table[0]\n",
    "    area_m2 = first_feature_table[1]\n",
    "    # prec_depth_mm = np.float64(vol_mm_x_m2) / area_m2\n",
    "    prec_depth_mm = vol_mm_x_m2 / area_m2 if area_m2 != 0 else 0\n",
    "\n",
    "    # timestamp in different format\n",
    "    t_s = ts_name_GivenIndex_2[3:]\n",
    "    time_stamp = dt.datetime.strptime(t_s, '%Y%m%d%H%M')\n",
    "\n",
    "    # GETTING PRECIPITATION DEPTHS CSV FILES\n",
    "    # Getting the precipitation depth (pd) for each subcatchment considering their timestamp, volume and area\n",
    "\n",
    "    field_names = ['SUB_CATCHMENT_ID', 'TIMESTAMP', 'PRECIPITATION_DEPTH', 'VOLUME', 'AREA']\n",
    "    out_pd_csv_file = '{}{}.csv'.format(out_folder, sc_name.iloc[df_sc_index_2,0])\n",
    "    first_feature_record = {'SUB_CATCHMENT_ID': sc_name.iloc[df_sc_index_2,0],\\\n",
    "        'TIMESTAMP': time_stamp,\\\n",
    "        'PRECIPITATION_DEPTH': prec_depth_mm,\\\n",
    "        'VOLUME': vol_mm_x_m2,\\\n",
    "        'AREA': area_m2}\n",
    "\n",
    "    with open(out_pd_csv_file, 'a+', newline='') as csv_file:\n",
    "        record_writer = DictWriter(csv_file, fieldnames=field_names)\n",
    "        record_writer.writerow(first_feature_record)\n",
    "\n",
    "# Finally, exitQgis() is called to remove the\n",
    "# provider and layer registries from memory\n",
    "# qgs.exitQgis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% #################################################\n",
    "\n",
    "def Get_Simplified_Raster(df_ts_index_1, df_sc_index_1):\n",
    "# arg1: each row index in dataframe Arg_TS_dt_index; it is a dataframe\n",
    "# arg2: all dataframe indexes in Arg_SC_dt_index; it is a dataframe\n",
    "\n",
    "    # POINT SHAPEFILE - PRECIPITACION DEPTH\n",
    "    # loading point shape file having the precipitation depth for each timestamp\n",
    "\n",
    "    point_shp_folder = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out/'\n",
    "    point_shp_file = '{}{}.shp'.format(point_shp_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "\n",
    "    # THIN PLATE SURFACE\n",
    "    # Generating the Thin Plate Surface (TPS) raster file (sdat file) by using processing\n",
    "\n",
    "    # Input variables for TPS\n",
    "    in_tps_shp_file = point_shp_file\n",
    "    x_min = 331480.0\n",
    "    x_max = 335660.0\n",
    "    y_min = 6244860.0\n",
    "    y_max = 6249400.0\n",
    "    crs_shp = '[EPSG:28356]'\n",
    "    cell_size = 1\n",
    "    # out_tps_sdat_file = '{}{}_tps.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "    # TPS via SAGA processing\n",
    "    exe_tps = processing.run(\"sagang:thinplatespline\",\\\n",
    "        {'SHAPES':in_tps_shp_file,\\\n",
    "        'FIELD':'Depth',\\\n",
    "        'TARGET_USER_XMIN TARGET_USER_XMAX TARGET_USER_YMIN TARGET_USER_YMAX':'{},{},{},{} {}'.format(x_min, x_max, y_min, y_max, crs_shp),\\\n",
    "        'TARGET_USER_SIZE':cell_size,\\\n",
    "        'TARGET_OUT_GRID':'TEMPORARY_OUTPUT',\\\n",
    "        'REGULARISATION':0.0001,\\\n",
    "        'SEARCH_RANGE':1,\\\n",
    "        'SEARCH_RADIUS':20000,\\\n",
    "        'SEARCH_POINTS_ALL':1,\\\n",
    "        'SEARCH_POINTS_MIN':16,\\\n",
    "        'SEARCH_POINTS_MAX':20,\\\n",
    "        'SEARCH_DIRECTION':0})\n",
    "\n",
    "\n",
    "    # SET ZEROS INSTEAD OF NEGATIVE VALUES FOR TPS SURFACE\n",
    "    # Changing negative values to zero via Raster calculator (RC)\n",
    "\n",
    "    # Input variables for RC\n",
    "    in_rc_sdat_file = exe_tps['TARGET_OUT_GRID']\n",
    "    # out_rc_sdat_file = '{}{}_rc.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "    # Raster calculator via QGIS processing\n",
    "    exe_rc = processing.run(\"qgis:rastercalculator\",\\\n",
    "        {'EXPRESSION':'(\"{0}@1\">=0.0)*\"{0}@1\"'.format(in_rc_sdat_file),\\\n",
    "        'LAYERS':[in_rc_sdat_file],\\\n",
    "        'CELLSIZE':0,\\\n",
    "        'EXTENT':None,\\\n",
    "        'CRS':None,\\\n",
    "        'OUTPUT':'TEMPORARY_OUTPUT'})\n",
    "\n",
    "\n",
    "    # CLIPPING TPS SURFACE\n",
    "    # Clipping raster (CLP) by mask layer (the mask is a polygon shapefile)\n",
    "\n",
    "    # Input variables for clipping raster by mask layer(CRBML)\n",
    "    in_clp_sdat_file = exe_rc['OUTPUT']\n",
    "    in_pol_shp_file = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Rainfall_Data/modified_from_Siming/SubcatSJoutlet_GDA_MGA_boundary.shp'\n",
    "    temp_out_clp_sdat_file = '{}temp_clp.sdat'.format(out_folder)         # out_clp_sdat_file = '{}{}_clp.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "    # CRBML via QGIS processing                 # exe_clp = \n",
    "    processing.run(\"gdal:cliprasterbymasklayer\",\\\n",
    "        {'INPUT':in_clp_sdat_file,\\\n",
    "        'MASK':in_pol_shp_file,\\\n",
    "        'SOURCE_CRS':None,\\\n",
    "        'TARGET_CRS':None,\\\n",
    "        'NODATA':None,\\\n",
    "        'ALPHA_BAND':False,\\\n",
    "        'CROP_TO_CUTLINE':True,\\\n",
    "        'KEEP_RESOLUTION':False,\\\n",
    "        'SET_RESOLUTION':False,\\\n",
    "        'X_RESOLUTION':None,\\\n",
    "        'Y_RESOLUTION':None,\\\n",
    "        'MULTITHREADING':False,\\\n",
    "        'OPTIONS':'',\\\n",
    "        'DATA_TYPE':0,\\\n",
    "        'EXTRA':'',\\\n",
    "        'OUTPUT':temp_out_clp_sdat_file})           # 'OUTPUT':'TEMPORARY_OUTPUT'})\n",
    "    \n",
    "    ts_name_GivenIndex = ts_name.iloc[df_ts_index_1,0]\n",
    "    # out_clip_sdat = exe_clp['OUTPUT']\n",
    "\n",
    "    # RUNNING THE FUNCTION Get_Vol_Area_shp\n",
    "\n",
    "    df_sc_index_1.apply(lambda x: Get_Vol_Area_shp(x.sc_index, temp_out_clp_sdat_file, ts_name_GivenIndex), axis=1)\n",
    "    # arg1: each row index in dataframe Arg_SC_dt_index; it is a dataframe\n",
    "    # arg2: only one sdat file produced by Arg_TS_dt_index in process; it is a variable which refers the file location\n",
    "    # arg3: only one temporary timestamp name for the sdat file given the index of the timestamp in process: it is a variable which refers the timestamp name given an index\n",
    "\n",
    "    # Arg_SC_dt_index['loc_sdat_file'] = temp_out_clp_sdat_file\n",
    "    # Arg_SC_dt_index['ts_index'] = ts_name_GivenIndex\n",
    "    # Arg_SC_dt_index.apply(lambda x: Get_Vol_Area_shp(x.sc_index, temp_out_clp_sdat_file, ts_name_GivenIndex), axis=1)\n",
    "    # Arg_SC_dt_index.apply(lambda x: Get_Vol_Area_shp(x.index, x.loc_sdat_file, x.ts_index), axis=1)\n",
    "    # np.vectorize(Get_Vol_Area_shp)(Arg_SC_dt_index, temp_out_clp_sdat_file, ts_name_GivenIndex)          # Arg_SC_dt_index.apply(Get_Vol_Area_shp, axis=1)\n",
    "    # np.vectorize(Get_Vol_Area_shp)(Arg_SC_dt_index, out_clip_sdat)          # (Arg_SC_dt_index)      # (Arg_SC_dt_index, out_clip_sdat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply path to qgis install location\n",
    "QgsApplication.setPrefixPath('C:/PROGRA~1/QGIS32~1.3/apps/qgis', True)\n",
    "\n",
    "# Create a reference to the QgsApplication.  Setting the\n",
    "# second argument to False disables the GUI.\n",
    "qgs = QgsApplication([], False)\n",
    "\n",
    "# Load providers\n",
    "qgs.initQgis()\n",
    "\n",
    "# Write your code here to load some layers, use processing\n",
    "# algorithms, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ts_199809090740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ts_199809090745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date_Time\n",
       "0  ts_199809090740\n",
       "1  ts_199809090745"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% READING TIMESTAMP NAMES FROM CSV FILE\n",
    "# reading timestamp (ts) names from a file to assign them to new file names\n",
    "\n",
    "loc_ts_folder = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out/'\n",
    "loc_ts_csv_file = '{}SHP_Filename.csv'.format(loc_ts_folder)\n",
    "ts_name = pd.read_csv(loc_ts_csv_file)\n",
    "ts_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sc_0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sc_0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sc_0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sc_0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sc_0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>sc_1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>sc_1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>sc_1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>sc_1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>sc_1534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1534 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sc\n",
       "0     sc_0001\n",
       "1     sc_0002\n",
       "2     sc_0003\n",
       "3     sc_0004\n",
       "4     sc_0005\n",
       "...       ...\n",
       "1529  sc_1530\n",
       "1530  sc_1531\n",
       "1531  sc_1532\n",
       "1532  sc_1533\n",
       "1533  sc_1534\n",
       "\n",
       "[1534 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% READING SUBCATCHMENTS NAMES FROM CSV FILE\n",
    "# reading subcatchment (sc) names from a file to assign them to new file names\n",
    "\n",
    "loc_sc_folder = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Rainfall_Data/modified_from_Siming/SC/'\n",
    "loc_sc_csv_file = '{}Sub_catchments.csv'.format(loc_sc_folder)\n",
    "sc_name = pd.read_csv(loc_sc_csv_file)\n",
    "sc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out2/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% OUTPUT FOLDER\n",
    "# Folder where all the results will be stored\n",
    "out_folder = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out2/'\n",
    "out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_index\n",
       "0         0\n",
       "1         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% DECLARING ARGUMENTS FOR TIMESTAMPS\n",
    "# the number of rows or total number of point shafiles\n",
    "\n",
    "Arg_TS_dt_index = pd.DataFrame()\n",
    "Arg_TS_dt_index['ts_index'] = pd.Series(range(ts_name.shape[0]))\n",
    "# Arg_TS_dt_index = np.arange(ts_name.shape[0])\n",
    "Arg_TS_dt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>1533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1534 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sc_index\n",
       "0            0\n",
       "1            1\n",
       "2            2\n",
       "3            3\n",
       "4            4\n",
       "...        ...\n",
       "1529      1529\n",
       "1530      1530\n",
       "1531      1531\n",
       "1532      1532\n",
       "1533      1533\n",
       "\n",
       "[1534 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% DECLARING ARGUMENTS FOR SUBCATCHMENTS\n",
    "# the number of rows or total number of subcatchments\n",
    "\n",
    "Arg_SC_dt_index = pd.DataFrame()\n",
    "Arg_SC_dt_index['sc_index'] = pd.Series(range(sc_name.shape[0]))\n",
    "# Arg_SC_dt_index = np.arange(sc_name.shape[0])\n",
    "Arg_SC_dt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arg_TS_dt_index.apply(lambda x: Get_Simplified_Raster(x.ts_index, Arg_SC_dt_index), axis=1)\n",
    "# arg1: each row index in dataframe Arg_TS_dt_index; it is a dataframe\n",
    "# arg2: all dataframe indexes in Arg_SC_dt_index; it is a dataframe\n",
    "\n",
    "# np.vectorize(Get_Simplified_Raster)(Arg_TS_dt_index)\n",
    "\n",
    "def Get_Simplified_Raster(df_ts_index_1, df_sc_index_1):\n",
    "# arg1: each row index in dataframe Arg_TS_dt_index; it is a dataframe\n",
    "# arg2: all dataframe indexes in Arg_SC_dt_index; it is a dataframe\n",
    "\n",
    "def Get_Vol_Area_shp(df_sc_index_2, temp_var_clip_sdat_file_loc, ts_name_GivenIndex_2):          # (df_sc_index_2):          # (df_sc_index_2, temp_var_clip_sdat_file_loc)\n",
    "# arg1: each row index in dataframe Arg_SC_dt_index; it is a dataframe\n",
    "# arg2: only one sdat file produced by Arg_TS_dt_index in process; it is a variable which refers the file location\n",
    "# arg3: only one temporary timestamp name for the sdat file given the index of the timestamp in process: it is a variable which refers the timestamp name given an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_index    0\n",
      "Name: 0, dtype: int64\n",
      "\n",
      "\n",
      "      sc_index\n",
      "0            0\n",
      "1            1\n",
      "2            2\n",
      "3            3\n",
      "4            4\n",
      "...        ...\n",
      "1529      1529\n",
      "1530      1530\n",
      "1531      1531\n",
      "1532      1532\n",
      "1533      1533\n",
      "\n",
      "[1534 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_ts_index_1 = Arg_TS_dt_index.loc[0]\n",
    "df_sc_index_1 = Arg_SC_dt_index\n",
    "print(df_ts_index_1, df_sc_index_1, sep=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_index    0\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_index_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ts_199809090740\n",
       "Name: Date_Time, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_name.iloc[df_ts_index_1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out/\n",
      "\n",
      "C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out/0    ts_199809090740\n",
      "Name: Date_Time, dtype: object.shp\n"
     ]
    }
   ],
   "source": [
    "# POINT SHAPEFILE - PRECIPITACION DEPTH\n",
    "# loading point shape file having the precipitation depth for each timestamp\n",
    "\n",
    "point_shp_folder = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out/'\n",
    "point_shp_file = '{}{}.shp'.format(point_shp_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "print(point_shp_folder, point_shp_file, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qgis\n",
    "from qgis.core import *\n",
    "from qgis.core import QgsApplication\n",
    "from qgis.core import QgsProject\n",
    "from qgis.core import QgsProcessingFeedback\n",
    "from qgis.core import QgsVectorLayer\n",
    "from qgis.analysis import QgsNativeAlgorithms\n",
    "import processing\n",
    "from processing.core.Processing import Processing\n",
    "\n",
    "Processing.initialize()\n",
    "QgsApplication.processingRegistry().addProvider(QgsNativeAlgorithms()) \n",
    "\n",
    "Processing.initialize()\n",
    "# Processing.updateAlgsList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIN PLATE SURFACE\n",
    "# Generating the Thin Plate Surface (TPS) raster file (sdat file) by using processing\n",
    "\n",
    "# Input variables for TPS\n",
    "in_tps_shp_file = point_shp_file\n",
    "x_min = 331480.0\n",
    "x_max = 335660.0\n",
    "y_min = 6244860.0\n",
    "y_max = 6249400.0\n",
    "crs_shp = '[EPSG:28356]'\n",
    "cell_size = 1\n",
    "out_tps_sdat_file = '{}{}_tps.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "QgsProcessingException",
     "evalue": "Error: Algorithm sagang:thinplatespline not found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQgsProcessingException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TPS via SAGA processing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m exe_tps \u001b[38;5;241m=\u001b[39m processing\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msagang:thinplatespline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\\\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHAPES\u001b[39m\u001b[38;5;124m'\u001b[39m:in_tps_shp_file,\\\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIELD\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepth\u001b[39m\u001b[38;5;124m'\u001b[39m,\\\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET_USER_XMIN TARGET_USER_XMAX TARGET_USER_YMIN TARGET_USER_YMAX\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x_min, x_max, y_min, y_max, crs_shp),\\\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET_USER_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m:cell_size,\\\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET_OUT_GRID\u001b[39m\u001b[38;5;124m'\u001b[39m:out_tps_sdat_file,\\\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREGULARISATION\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.0001\u001b[39m,\\\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_RANGE\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\\\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_RADIUS\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m20000\u001b[39m,\\\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_POINTS_ALL\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\\\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_POINTS_MIN\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m16\u001b[39m,\\\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_POINTS_MAX\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m20\u001b[39m,\\\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_DIRECTION\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m})\n\u001b[0;32m     16\u001b[0m exe_tps\n",
      "File \u001b[1;32m~\\.conda\\envs\\qgis_env\\Library\\python\\plugins\\processing\\tools\\general.py:108\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(algOrName, parameters, onFinish, feedback, context, is_child_algorithm)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[39mExecutes given algorithm and returns its outputs as dictionary object.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39m:rtype: Union[dict, None]\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mif\u001b[39;00m onFinish \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_child_algorithm:\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mreturn\u001b[39;00m Processing\u001b[39m.\u001b[39;49mrunAlgorithm(algOrName, parameters, onFinish, feedback, context)\n\u001b[0;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39m# for child algorithms, we disable to default post-processing step where layer ownership\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[39m# is transferred from the context to the caller. In this case, we NEED the ownership to remain\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[39m# with the context, so that further steps in the algorithm have guaranteed access to the layer.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mpost_process\u001b[39m(_alg, _context, _feedback):\n",
      "File \u001b[1;32m~\\.conda\\envs\\qgis_env\\Library\\python\\plugins\\processing\\core\\Processing.py:156\u001b[0m, in \u001b[0;36mProcessing.runAlgorithm\u001b[1;34m(algOrName, parameters, onFinish, feedback, context)\u001b[0m\n\u001b[0;32m    154\u001b[0m     msg \u001b[39m=\u001b[39m Processing\u001b[39m.\u001b[39mtr(\u001b[39m'\u001b[39m\u001b[39mError: Algorithm \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mformat(algOrName)\n\u001b[0;32m    155\u001b[0m     feedback\u001b[39m.\u001b[39mreportError(msg)\n\u001b[1;32m--> 156\u001b[0m     \u001b[39mraise\u001b[39;00m QgsProcessingException(msg)\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     context \u001b[39m=\u001b[39m dataobjects\u001b[39m.\u001b[39mcreateContext(feedback)\n",
      "\u001b[1;31mQgsProcessingException\u001b[0m: Error: Algorithm sagang:thinplatespline not found\n"
     ]
    }
   ],
   "source": [
    "# TPS via SAGA processing\n",
    "exe_tps = processing.run(\"sagang:thinplatespline\",\\\n",
    "    {'SHAPES':in_tps_shp_file,\\\n",
    "    'FIELD':'Depth',\\\n",
    "    'TARGET_USER_XMIN TARGET_USER_XMAX TARGET_USER_YMIN TARGET_USER_YMAX':'{},{},{},{} {}'.format(x_min, x_max, y_min, y_max, crs_shp),\\\n",
    "    'TARGET_USER_SIZE':cell_size,\\\n",
    "    'TARGET_OUT_GRID':out_tps_sdat_file,\\\n",
    "    'REGULARISATION':0.0001,\\\n",
    "    'SEARCH_RANGE':1,\\\n",
    "    'SEARCH_RADIUS':20000,\\\n",
    "    'SEARCH_POINTS_ALL':1,\\\n",
    "    'SEARCH_POINTS_MIN':16,\\\n",
    "    'SEARCH_POINTS_MAX':20,\\\n",
    "    'SEARCH_DIRECTION':0})\n",
    "\n",
    "exe_tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "    # TPS via SAGA processing\n",
    "    exe_tps = processing.run(\"sagang:thinplatespline\",\\\n",
    "        {'SHAPES':in_tps_shp_file,\\\n",
    "        'FIELD':'Depth',\\\n",
    "        'TARGET_USER_XMIN TARGET_USER_XMAX TARGET_USER_YMIN TARGET_USER_YMAX':'{},{},{},{} {}'.format(x_min, x_max, y_min, y_max, crs_shp),\\\n",
    "        'TARGET_USER_SIZE':cell_size,\\\n",
    "        'TARGET_OUT_GRID':'TEMPORARY_OUTPUT',\\\n",
    "        'REGULARISATION':0.0001,\\\n",
    "        'SEARCH_RANGE':1,\\\n",
    "        'SEARCH_RADIUS':20000,\\\n",
    "        'SEARCH_POINTS_ALL':1,\\\n",
    "        'SEARCH_POINTS_MIN':16,\\\n",
    "        'SEARCH_POINTS_MAX':20,\\\n",
    "        'SEARCH_DIRECTION':0})\n",
    "\n",
    "\n",
    "    # SET ZEROS INSTEAD OF NEGATIVE VALUES FOR TPS SURFACE\n",
    "    # Changing negative values to zero via Raster calculator (RC)\n",
    "\n",
    "    # Input variables for RC\n",
    "    in_rc_sdat_file = exe_tps['TARGET_OUT_GRID']\n",
    "    # out_rc_sdat_file = '{}{}_rc.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "    # Raster calculator via QGIS processing\n",
    "    exe_rc = processing.run(\"qgis:rastercalculator\",\\\n",
    "        {'EXPRESSION':'(\"{0}@1\">=0.0)*\"{0}@1\"'.format(in_rc_sdat_file),\\\n",
    "        'LAYERS':[in_rc_sdat_file],\\\n",
    "        'CELLSIZE':0,\\\n",
    "        'EXTENT':None,\\\n",
    "        'CRS':None,\\\n",
    "        'OUTPUT':'TEMPORARY_OUTPUT'})\n",
    "\n",
    "\n",
    "    # CLIPPING TPS SURFACE\n",
    "    # Clipping raster (CLP) by mask layer (the mask is a polygon shapefile)\n",
    "\n",
    "    # Input variables for clipping raster by mask layer(CRBML)\n",
    "    in_clp_sdat_file = exe_rc['OUTPUT']\n",
    "    in_pol_shp_file = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Rainfall_Data/modified_from_Siming/SubcatSJoutlet_GDA_MGA_boundary.shp'\n",
    "    temp_out_clp_sdat_file = '{}temp_clp.sdat'.format(out_folder)         # out_clp_sdat_file = '{}{}_clp.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "    # CRBML via QGIS processing                 # exe_clp = \n",
    "    processing.run(\"gdal:cliprasterbymasklayer\",\\\n",
    "        {'INPUT':in_clp_sdat_file,\\\n",
    "        'MASK':in_pol_shp_file,\\\n",
    "        'SOURCE_CRS':None,\\\n",
    "        'TARGET_CRS':None,\\\n",
    "        'NODATA':None,\\\n",
    "        'ALPHA_BAND':False,\\\n",
    "        'CROP_TO_CUTLINE':True,\\\n",
    "        'KEEP_RESOLUTION':False,\\\n",
    "        'SET_RESOLUTION':False,\\\n",
    "        'X_RESOLUTION':None,\\\n",
    "        'Y_RESOLUTION':None,\\\n",
    "        'MULTITHREADING':False,\\\n",
    "        'OPTIONS':'',\\\n",
    "        'DATA_TYPE':0,\\\n",
    "        'EXTRA':'',\\\n",
    "        'OUTPUT':temp_out_clp_sdat_file})           # 'OUTPUT':'TEMPORARY_OUTPUT'})\n",
    "    \n",
    "    ts_name_GivenIndex = ts_name.iloc[df_ts_index_1,0]\n",
    "    # out_clip_sdat = exe_clp['OUTPUT']\n",
    "\n",
    "    # RUNNING THE FUNCTION Get_Vol_Area_shp\n",
    "\n",
    "    df_sc_index_1.apply(lambda x: Get_Vol_Area_shp(x.sc_index, temp_out_clp_sdat_file, ts_name_GivenIndex), axis=1)\n",
    "    # arg1: each row index in dataframe Arg_SC_dt_index; it is a dataframe\n",
    "    # arg2: only one sdat file produced by Arg_TS_dt_index in process; it is a variable which refers the file location\n",
    "    # arg3: only one temporary timestamp name for the sdat file given the index of the timestamp in process: it is a variable which refers the timestamp name given an index\n",
    "\n",
    "    # Arg_SC_dt_index['loc_sdat_file'] = temp_out_clp_sdat_file\n",
    "    # Arg_SC_dt_index['ts_index'] = ts_name_GivenIndex\n",
    "    # Arg_SC_dt_index.apply(lambda x: Get_Vol_Area_shp(x.sc_index, temp_out_clp_sdat_file, ts_name_GivenIndex), axis=1)\n",
    "    # Arg_SC_dt_index.apply(lambda x: Get_Vol_Area_shp(x.index, x.loc_sdat_file, x.ts_index), axis=1)\n",
    "    # np.vectorize(Get_Vol_Area_shp)(Arg_SC_dt_index, temp_out_clp_sdat_file, ts_name_GivenIndex)          # Arg_SC_dt_index.apply(Get_Vol_Area_shp, axis=1)\n",
    "    # np.vectorize(Get_Vol_Area_shp)(Arg_SC_dt_index, out_clip_sdat)          # (Arg_SC_dt_index)      # (Arg_SC_dt_index, out_clip_sdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out/0    ts_199809090740\n",
      "Name: Date_Time, dtype: object.shp\n"
     ]
    }
   ],
   "source": [
    "# POINT SHAPEFILE - PRECIPITACION DEPTH\n",
    "    # loading point shape file having the precipitation depth for each timestamp\n",
    "\n",
    "point_shp_folder = 'C:/Users/HOLGER/Downloads/SharedFiles_ProfJames/Testing_Files/out/'\n",
    "point_shp_file = '{}{}.shp'.format(point_shp_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "print(point_shp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "QgsProcessingException",
     "evalue": "Error: Algorithm sagang:thinplatespline not found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQgsProcessingException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m cell_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# out_tps_sdat_file = '{}{}_tps.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# TPS via SAGA processing\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m exe_tps \u001b[38;5;241m=\u001b[39m processing\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msagang:thinplatespline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\\\n\u001b[0;32m     16\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHAPES\u001b[39m\u001b[38;5;124m'\u001b[39m:in_tps_shp_file,\\\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFIELD\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepth\u001b[39m\u001b[38;5;124m'\u001b[39m,\\\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET_USER_XMIN TARGET_USER_XMAX TARGET_USER_YMIN TARGET_USER_YMAX\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x_min, x_max, y_min, y_max, crs_shp),\\\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET_USER_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m:cell_size,\\\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET_OUT_GRID\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEMPORARY_OUTPUT\u001b[39m\u001b[38;5;124m'\u001b[39m,\\\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREGULARISATION\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.0001\u001b[39m,\\\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_RANGE\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\\\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_RADIUS\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m20000\u001b[39m,\\\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_POINTS_ALL\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\\\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_POINTS_MIN\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m16\u001b[39m,\\\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_POINTS_MAX\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m20\u001b[39m,\\\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEARCH_DIRECTION\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m})\n",
      "File \u001b[1;32m~\\.conda\\envs\\qgis_env\\Library\\python\\plugins\\processing\\tools\\general.py:108\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(algOrName, parameters, onFinish, feedback, context, is_child_algorithm)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03mExecutes given algorithm and returns its outputs as dictionary object.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m:rtype: Union[dict, None]\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m onFinish \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_child_algorithm:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mProcessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunAlgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgOrName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monFinish\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeedback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# for child algorithms, we disable to default post-processing step where layer ownership\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# is transferred from the context to the caller. In this case, we NEED the ownership to remain\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# with the context, so that further steps in the algorithm have guaranteed access to the layer.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost_process\u001b[39m(_alg, _context, _feedback):\n",
      "File \u001b[1;32m~\\.conda\\envs\\qgis_env\\Library\\python\\plugins\\processing\\core\\Processing.py:156\u001b[0m, in \u001b[0;36mProcessing.runAlgorithm\u001b[1;34m(algOrName, parameters, onFinish, feedback, context)\u001b[0m\n\u001b[0;32m    154\u001b[0m     msg \u001b[38;5;241m=\u001b[39m Processing\u001b[38;5;241m.\u001b[39mtr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError: Algorithm \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(algOrName)\n\u001b[0;32m    155\u001b[0m     feedback\u001b[38;5;241m.\u001b[39mreportError(msg)\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QgsProcessingException(msg)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     context \u001b[38;5;241m=\u001b[39m dataobjects\u001b[38;5;241m.\u001b[39mcreateContext(feedback)\n",
      "\u001b[1;31mQgsProcessingException\u001b[0m: Error: Algorithm sagang:thinplatespline not found\n"
     ]
    }
   ],
   "source": [
    "# THIN PLATE SURFACE\n",
    "# Generating the Thin Plate Surface (TPS) raster file (sdat file) by using processing\n",
    "\n",
    "# Input variables for TPS\n",
    "in_tps_shp_file = point_shp_file\n",
    "x_min = 331480.0\n",
    "x_max = 335660.0\n",
    "y_min = 6244860.0\n",
    "y_max = 6249400.0\n",
    "crs_shp = '[EPSG:28356]'\n",
    "cell_size = 1\n",
    "# out_tps_sdat_file = '{}{}_tps.sdat'.format(out_folder, ts_name.iloc[df_ts_index_1,0])\n",
    "\n",
    "# TPS via SAGA processing\n",
    "exe_tps = processing.run(\"sagang:thinplatespline\",\\\n",
    "    {'SHAPES':in_tps_shp_file,\\\n",
    "    'FIELD':'Depth',\\\n",
    "    'TARGET_USER_XMIN TARGET_USER_XMAX TARGET_USER_YMIN TARGET_USER_YMAX':'{},{},{},{} {}'.format(x_min, x_max, y_min, y_max, crs_shp),\\\n",
    "    'TARGET_USER_SIZE':cell_size,\\\n",
    "    'TARGET_OUT_GRID':'TEMPORARY_OUTPUT',\\\n",
    "    'REGULARISATION':0.0001,\\\n",
    "    'SEARCH_RANGE':1,\\\n",
    "    'SEARCH_RADIUS':20000,\\\n",
    "    'SEARCH_POINTS_ALL':1,\\\n",
    "    'SEARCH_POINTS_MIN':16,\\\n",
    "    'SEARCH_POINTS_MAX':20,\\\n",
    "    'SEARCH_DIRECTION':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% RUNNING THE FUNCTION Get_Simplified_Raster\n",
    "\n",
    "Arg_TS_dt_index.apply(lambda x: Get_Simplified_Raster(x.ts_index, Arg_SC_dt_index), axis=1)\n",
    "# arg1: each row index in dataframe Arg_TS_dt_index; it is a dataframe\n",
    "# arg2: all dataframe indexes in Arg_SC_dt_index; it is a dataframe\n",
    "\n",
    "# np.vectorize(Get_Simplified_Raster)(Arg_TS_dt_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ENDING TIME\n",
    "\n",
    "ending_time = time.time()\n",
    "print('Done! in {}'.format(ending_time - starting_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgs.exitQgis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('qgis_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f507a3b1b233680011a04a7dff691513f5d521a8540dfe8352f99843ef706fd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
